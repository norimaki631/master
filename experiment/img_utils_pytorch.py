#! /usr/bin/env python
# -*- coding: utf-8 -*-

"""
Image deformation using moving least squares.

    * Affine deformation
    * Similarity deformation
    * Rigid deformation

For more details please refer to the Chinese documentation: 
    
    ./doc/Image Deformation.pdf

or the original paper: 
    
    Image deformation using moving least squares
    Schaefer, Mcphail, Warren. 

Note:
    In the original paper, the author missed the weight w_j in formular (5).
    In addition, all the formulars in section 2.1 miss the w_j. 
    And I have corrected this point in my documentation.

@author: Jian-Wei ZHANG
@email: zjw.cs@zju.edu.cn
@date: 2022/01/12: PyTorch implementation
"""

import torch

from interp_torch import interp



def mls_rigid_deformation(vy, vx, p, q, alpha=1.0, eps=1e-8):
    """ Rigid deformation
    
    Parameters
    ----------
    vx, vy: torch.Tensor
        coordinate grid, generated by torch.meshgrid(gridX, gridY)
    p: torch.Tensor
        an array with size [n, 2], original control points, in (y, x) formats
    q: torch.Tensor
        an array with size [n, 2], final control points, in (y, x) formats
    alpha: float
        parameter used by weights
    eps: float
        epsilon
    
    Return
    ------
        A deformed image.
    """
    device = q.device
    q = q.short()
    p = p.short()

    # Exchange p and q and hence we transform destination pixels to the corresponding source pixels.
    p, q = q, p

    grow = vx.shape[0]  # grid rows
    gcol = vx.shape[1]  # grid cols
    ctrls = p.shape[0]  # control points

    # Compute
    reshaped_p = p.reshape(ctrls, 2, 1, 1)                                              # [ctrls, 2, 1, 1]
    reshaped_v = torch.cat((vx.reshape(1, grow, gcol), vy.reshape(1, grow, gcol)), dim=0)      # [2, grow, gcol]
    
    w = 1.0 / (torch.sum((reshaped_p - reshaped_v).float() ** 2, dim=1) + eps) ** alpha    # [ctrls, grow, gcol]
    w /= torch.sum(w, dim=0, keepdim=True)                                               # [ctrls, grow, gcol]
    
    pstar = torch.zeros((2, grow, gcol), dtype=torch.float32).to(device)
    for i in range(ctrls):
        pstar += w[i] * reshaped_p[i]                                                   # [2, grow, gcol]

    vpstar = reshaped_v - pstar                                                         # [2, grow, gcol]
    reshaped_vpstar = vpstar.reshape(2, 1, grow, gcol)                                  # [2, 1, grow, gcol]
    neg_vpstar_verti = vpstar[[1, 0],...]                                               # [2, grow, gcol]
    neg_vpstar_verti[1,...] = -neg_vpstar_verti[1,...]                                  
    reshaped_neg_vpstar_verti = neg_vpstar_verti.reshape(2, 1, grow, gcol)              # [2, 1, grow, gcol]
    mul_right = torch.cat((reshaped_vpstar, reshaped_neg_vpstar_verti), dim=1)    # [2, 2, grow, gcol]
    reshaped_mul_right = mul_right.reshape(2, 2, grow, gcol)                            # [2, 2, grow, gcol]

    # Calculate q
    reshaped_q = q.reshape((ctrls, 2, 1, 1))                                            # [ctrls, 2, 1, 1]
    qstar = torch.zeros((2, grow, gcol), dtype=torch.float32).to(device)
    for i in range(ctrls):
        qstar += w[i] * reshaped_q[i]                                                   # [2, grow, gcol]
    
    temp = torch.zeros((grow, gcol, 2), dtype=torch.float32).to(device)
    for i in range(ctrls):
        phat = reshaped_p[i] - pstar                                                    # [2, grow, gcol]
        reshaped_phat = phat.reshape(1, 2, grow, gcol)                                  # [1, 2, grow, gcol]
        reshaped_w = w[i].reshape(1, 1, grow, gcol)                                     # [1, 1, grow, gcol]
        neg_phat_verti = phat[[1, 0]]                                                   # [2, grow, gcol]
        neg_phat_verti[1] = -neg_phat_verti[1]
        reshaped_neg_phat_verti = neg_phat_verti.reshape(1, 2, grow, gcol)              # [1, 2, grow, gcol]
        mul_left = torch.cat((reshaped_phat, reshaped_neg_phat_verti), dim=0)     # [2, 2, grow, gcol]
        
        A = torch.matmul((reshaped_w * mul_left).permute(2, 3, 0, 1), 
                        reshaped_mul_right.permute(2, 3, 0, 1))                       # [grow, gcol, 2, 2]

        qhat = reshaped_q[i] - qstar                                                    # [2, grow, gcol]
        reshaped_qhat = qhat.reshape(1, 2, grow, gcol).permute(2, 3, 0, 1)            # [grow, gcol, 1, 2]

        # Get final image transfomer -- 3-D array
        temp += torch.matmul(reshaped_qhat, A).reshape(grow, gcol, 2)                      # [grow, gcol, 2]

    temp = temp.permute(2, 0, 1)                                                      # [2, grow, gcol]
    normed_temp = torch.norm(temp, dim=0, keepdim=True)                           # [1, grow, gcol]
    normed_vpstar = torch.norm(vpstar, dim=0, keepdim=True)                       # [1, grow, gcol]
    transformers = temp / normed_temp * normed_vpstar  + qstar                          # [2, grow, gcol]
    nan_mask = normed_temp[0] == 0

    # Replace nan values by interpolated values
    nan_mask_flat = torch.nonzero(nan_mask.view(-1), as_tuple=True)[0]
    nan_mask_anti_flat = torch.nonzero(~nan_mask.view(-1), as_tuple=True)[0]
    transformers[0][nan_mask] = interp(nan_mask_flat, nan_mask_anti_flat, transformers[0][~nan_mask])
    transformers[1][nan_mask] = interp(nan_mask_flat, nan_mask_anti_flat, transformers[1][~nan_mask])

    # Remove the points outside the border
    transformers[transformers < 0] = 0
    transformers[0][transformers[0] > grow - 1] = 0
    transformers[1][transformers[1] > gcol - 1] = 0
    
    return transformers.long()
